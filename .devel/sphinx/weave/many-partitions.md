



(sec:many-partitions)=
# There Can Be Many Valid Partitions

We believe that it is in the very spirit of unsupervised learning
that for some datasets, **there might be multiple equally
valid/plausible/useful ways to partition them**
(see also {cite}`sdmc,LuxburgETAL2012:clustscienceart` for discussion).


## Alternative Labellings

This is why many benchmark sets in our suite come
with alternative labellings.
For instance, consider the {ref}`graves/zigzag_noisy <sec:suite-v1>`
dataset {cite}`graves`:



```python
import numpy as np
import clustbench
data_url = "https://github.com/gagolews/clustering-data-v1/raw/master"
benchmark = clustbench.load_dataset("graves", "zigzag_noisy", url=data_url)
```

It is equipped with two different reference partitions:



```python
len(benchmark.labels)
## 2
```

They are depicted below.




```python
import genieclust
for i in range(len(benchmark.labels)):
    y_true = benchmark.labels[i]
    k = max(y_true)
    plt.subplot(1, len(benchmark.labels), i+1)
    genieclust.plots.plot_scatter(
        benchmark.data, labels=y_true-1,
        axis="equal", title=f"labels{i}; k={k}"
    )

plt.show()
```

(fig:many-partitions)=
```{figure} many-partitions-figures/many-partitions-1.*
There can be many equally valid partitions.
```



## Predicted vs Best-Matching Reference Labelling

An algorithm should be rewarded for finding a partition
that matches at least one of the reference ones.
This might require running the method multiple times
to find partitions of different cardinalities.


::::{important}
The outputs generated by a single algorithm
should be evaluated against all the available reference labellings
and the *maximal* similarity score should be reported.
::::



An example featuring the outputs generated by
[*Genie*](https://genieclust.gagolewski.com):



```python
g = genieclust.Genie()
scores = []
for i in range(len(benchmark.labels)):
    y_true = benchmark.labels[i]
    k = max(y_true)

    # find a k-clustering:
    g.set_params(n_clusters=k)
    y_pred = g.fit_predict(benchmark.data) + 1  # +1 to make cluster IDs in 1..k

    # external cluster validity measure (skip noise points):
    scores.append(score :=
        genieclust.compare_partitions.adjusted_asymmetric_accuracy(
            y_true[y_true>0],
            y_pred[y_true>0]
    ))

    # scatterplot:
    plt.subplot(1, len(benchmark.labels), i+1)
    genieclust.plots.plot_scatter(
        benchmark.data, labels=y_pred-1,
        axis="equal", title=f"Genie; k={k} (labels{i}: AAA={score:.2f})"
    )

plt.show()
```

(fig:many-partitions-genie)=
```{figure} many-partitions-figures/many-partitions-genie-3.*
Results generated by Genie.
```

The best score is thus:



```python
max(scores)
## 1.0
```


::::{note}
Experts (like you) are encouraged to {ref}`contribute <sec:contributing>`
new reference labellings.
See also the *{ref}`Colouriser <sec:colouriser>`* class
for a way to generate label vectors interactively (for planar datasets).
::::
