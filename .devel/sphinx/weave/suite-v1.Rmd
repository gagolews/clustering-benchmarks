(sec:suite-v1)=
# Benchmark Suite (v1)

TO DO...

{cite}`GravesPedrycz2010:kernelfuzzyclust`

{cite}`ThrunUltsch2020:fcps`

{cite}`kmsix`

{cite}`uci`


> Datasets are available at <https://github.com/gagolews/clustering-data-v1>.
> Raw results generated by many clustering algorithms can be found at
> <https://github.com/gagolews/clustering-results-v1/>.




**Version 1** of the benchmark datasets suite, dated 8 May 2020,
is available at <https://github.com/gagolews/clustering-data-v1>
([DOI: 10.5281/zenodo.3815066](https://doi.org/10.5281/zenodo.3815066)).
Raw results generated by many clustering algorithms can be found at
<https://github.com/gagolews/clustering-results-v1/>.
They are provided solely for research purposes,
unless stated otherwise. Please cite the literature references mentioned
in the description files corresponding to each dataset if you use
them in your publications.



## Data Sources

There is some inherent overlap between the original databases.
We have tried to resolve any conflicts in the *best* possible manner.


1. `fcps` -
    the Fundamental Clustering Problem Suite proposed by A. Ultsch (2005)
    from the Marburg University, Germany

    Each dataset consists of 212-4096 observations in 2-3 dimensions.

    Source: <https://www.uni-marburg.de/fb12/arbeitsgruppen/datenbionik/data>


2. `graves` -
    *synthetic data sets* considered in the paper (Graves and Pedrycz, 2010)

    Each dataset consists of 200-1050 observations in 2 dimensions.


3. `mnist` -
    LeCun's MNIST database of handwritten digits
    and Zalando's Fashion-MNIST dataset.



4. `other`:

    * `hdbscan` - a dataset used for demonstrating the outputs of the
        [Python implementation](https://github.com/scikit-learn-contrib/hdbscan)
        of the HDBSCAN (Campello et al., 2015) algorithm

        Source: <https://github.com/scikit-learn-contrib/hdbscan/blob/master/notebooks/clusterable_data.npy>

    * `chameleon_t4_8k`, `chameleon_t5_8k`, `chameleon_t7_10k`,
       `chameleon_t8_8k` - datasets supposedly related to the
       CHAMELEON algorithm (Karypis et al., 1999).

       Source: <http://glaros.dtc.umn.edu/gkhome/cluto/cluto/download>

       In fact, (Karypis et al., 1999) studies two of the above
       and two quite different ones:
       `chameleon_t7_10k` is named `DS3` in the paper, while
       `chameleon_t8_8k` is referred to as `DS4`.
       The `DS2` set looks like a more noisy version of `fcps_twodiamonds`.
       Interestingly,  [SIPU](https://cs.joensuu.fi/sipu/datasets/) also provides
       `chameleon_t4_8k` and suggests its relation with CHAMELEON, but
       its screenshot does not appear in the paper.

    * `iris`, `iris5` - "the" (for discussion see Bezdek et al., 1999)
        famous Iris dataset and its imbalanced version considered
        in (Gagolewski et al., 2016).

    as well as some datasets of unknown/unconfirmed origin
    (TODO: help needed).


5. `sipu` -
    datasets available at the SIPU (Speech and Image Processing Unit,
    School of Computing, University of Eastern Finland) website

    Many datasets were proposed by P. Fränti et al., see
    (Fränti, Sieranoja, 2018). However, some datasets gathered from other
    sources (see the referenced catalogue for citations) but available
    for download via the SIPU website are also included.

    Source: <https://cs.joensuu.fi/sipu/datasets/>

    We do not include the `G2` sets as the cluster variances
    should be corrected for space dimensionality, see `g2mg` below
    for an alternative.
    `Birch3` is not included as no ground-truth labels were provided.
    We excluded the `DIM`-sets as they turn out to be too easy
    for most algorithms.

6. `uci` -
    a selection of datasets available at the University of California, Irvine,
    [Machine Learning Repository](http://archive.ics.uci.edu/ml/)
    (Dua and Graff, 2019)

    Some of these datasets in this selection were considered
    for benchmark purposes
    in - among others - (Graves and Pedrycz, 2010); they are
    also listed in the SIPU repository.
    Note that "the" Iris dataset is available elsewhere (see `other`).

7. `wut` -
    authored by the fantastic students
    of Marek's Python
    for Data Analysis course at Warsaw University of Technology:
    Przemysław Kosewski, Jędrzej Krauze, Eliza Kaczorek, Anna Gierlak,
    Adam Wawrzyniak, Aleksander Truszczyński, Mateusz Kobyłka and Michał Maciąg.


8. `g2mg` -
    a modified version of `G2`-sets from SIPU with variances
    dependent on datasets' dimensionalities, i.e., s*np.sqrt(d/2),
    which makes these problems more difficult.

    Each dataset consists of 2048 observations belonging
    to either of two Gaussian clusters in 1, 2, ..., 128 dimensions.

9. `h2mg` -
    two Gaussian-like hubs with spread dependent on datasets' dimensionalities

    Each dataset consists of 2048 observations in 1, 2, ..., 128 dimensions.
    Each point is sampled from a sphere centred at its own cluster's centre,
    of radius that follows the Gaussian distribution with a predefined scale.


::::{todo}
List of datasets, n, d, number of label vectors, numbers of labels, noise
::::


