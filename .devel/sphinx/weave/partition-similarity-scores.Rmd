(sec:partition-similarity-scores)=
# Partition Similarity Scores

In this section we review the partition similarity scores that are implemented
in the [*genieclust*](https://genieclust.gagolewski.com/) package for Python
and R.

Let $\mathbf{y}$ be a {ref}`label <sec:true-vs-predicted>`
vector representing {ref}`one <sec:many-partitions>` of the reference
$k$-partitions $\{X_1,\dots,X_k\}$ of a benchmark dataset $X$,
where $y_i\in[1:k]$ gives the true cluster number (ID) of the $i$-th object.

Furthermore, let $\hat{\mathbf{y}}$ be a label vector
encoding another partition, $\{\hat{X}_1,\dots,\hat{X}_l\}$,
which we would like to *relate* to the reference one, $\mathbf{y}$.
In our context, we assume that $\hat{\mathbf{y}}$ has been determined by some
clustering algorithm.


::::{note}
Below we assume $k \le l$, i.e., the true clustering
might theoretically be more coarse-grained than the reference one.
Also, any {ref}`noise points <sec:noise-points>` in $X$ have been removed
before the data analysis.
::::



::::{proof:example}
120 points in $\mathbb{R}^2$...

```{python}
import numpy as np
import pandas as pd
dataset = "https://github.com/gagolews/clustering-data-v1/raw/master/wut/x2"
X = np.loadtxt(dataset + ".data.gz")
y_true = np.loadtxt(dataset+".labels0.gz", dtype=np.intc)
k = max(y_true)
```

```{python}
import genieclust
g = genieclust.Genie(n_clusters=k)  # default parameters
y_genie = g.fit_predict(X) + 1
```


```{python}
np.random.seed(123)
y_random = np.random.choice(np.arange(k), len(y_true)) + 1  # sample from 1..k
```


```{python}
import sklearn.cluster
c = sklearn.cluster.KMeans(n_clusters=k)
y_kmeans = c.fit_predict(X) + 1
```

```{python echo=FALSE}
plt.figure(figsize=(plt.rcParams["figure.figsize"][0], )*2)  # HIDDEN
np.random.seed(123)  # HIDDEN
```

```{python partition-similarity-example-4,results="hide",fig.cap="The reference partition and three different clusterings that we would like to relate thereto"}
plt.subplot(2, 2, 1)
genieclust.plots.plot_scatter(X, labels=y_true-1)
plt.axis("equal")
plt.title("y_true")
plt.subplot(2, 2, 2)
genieclust.plots.plot_scatter(X, labels=y_genie-1)
plt.axis("equal")
plt.title("y_genie")
plt.subplot(2, 2, 3)
genieclust.plots.plot_scatter(X, labels=y_random-1)
plt.axis("equal")
plt.title("y_random")
plt.subplot(2, 2, 4)
genieclust.plots.plot_scatter(X, labels=y_kmeans-1)
plt.axis("equal")
plt.title("y_kmeans")
plt.show()
```

```{python echo=FALSE,results="hide"}
plt.close()  # resets graphical params
```
::::


## Why Not Accuracy?


TODO: genieclust function to relabel.....


Furthermore, let $\mathbf{C}$ be the confusion matrix with
$k$ rows and $l$ columns,
i.e., $c_{u,v}$ gives the number point indexes $i$ for which $y_i=u$
and $\hat{y}_v$. In other words, $c_{u,v}$ gives the number of points
from the $u$-th reference cluster that the clustering algorithm
classified as belonging to the $v$-th group.




```{python}
# (C := genieclust.compare_partitions.confusion_matrix(y_true, y_pred))
```




normalized_confusion_matrix
pivoting... permutes the rows and columns
        so that the sum of the elements of the main diagonal is the largest
        possible



say that this is different than accuracy in classification





genieclust:: bibliography, compare_partitions.pyx

some axioms

Every index except `mi_score` (which computes the mutual
information score) outputs the value of 1.0 if two identical partitions
are given.
Note that partitions are always defined up to a bijection of the set of
possible labels, e.g., (1, 1, 2, 1) and (4, 4, 2, 4)
represent the same 2-partition.

    .. [1]
        Hubert L., Arabie P., Comparing Partitions,
        *Journal of Classification* 2(1), 1985, 193-218.

    .. [2]
        Rendon E., Abundez I., Arizmendi A., Quiroz E.M.,
        Internal versus external cluster validation indexes,
        *International Journal of Computers and Communications* 5(1), 2011,
        27-34.

    .. [3]
        Rezaei M., Franti P., Set matching measures for external cluster validity,
        *IEEE Transactions on Knowledge and Data Mining* 28(8), 2016,
        2173-2186. https://doi.org/10.1109/TKDE.2016.2551240.

    .. [4]
        Vinh N.X., Epps J., Bailey J.,
        Information theoretic measures for clusterings comparison:
        Variants, properties, normalization and correction for chance,
        *Journal of Machine Learning Research* 11, 2010, 2837-2854.

`normalized_accuracy` is defined as
:math:`(\\mathrm{Accuracy}(C_\\sigma)-1/L)/(1-1/L)`,
where :math:`C_\\sigma` is a version of the confusion matrix
for given `x` and `y`, :math:`K \\leq L`, with columns permuted
based on the solution to the Maximal Linear Sum Assignment Problem
(see `normalize_confusion_matrix`).
:math:`\\mathrm{Accuracy}(C_\\sigma)` is sometimes referred to as Purity,
e.g., in [2]_.

`pair_sets_index` gives the Pair Sets Index (PSI)
adjusted for chance [3]_, :math:`K \\leq L`.
Pairing is based on the solution to the Linear Sum Assignment Problem
of a transformed version of the confusion matrix.




`rand_score` gives the Rand score (the "probability" of agreement
between the two partitions) and `adjusted_rand_score` is its version
corrected for chance [1]_ (especially Eqs. (2) and (4) therein):
its expected value is 0.0 for two independent
partitions. Due to the adjustment, the resulting index might also
be negative for some inputs.

Similarly, `fm_score` gives the Fowlkes-Mallows (FM) score
and `adjusted_fm_score` is its adjusted-for-chance version [1]_.

Note that both the (unadjusted) Rand and FM scores are bounded from below
by :math:`1/(K+1)` if :math:`K = L`, hence their adjusted versions
are preferred.

`mi_score`, `adjusted_mi_score` and `normalized_mi_score` are
information-theoretic indices based on mutual information,
see the definition of :math:`\\mathrm{AMI}_\\mathrm{sum}`
and :math:`\\mathrm{NMI}_\\mathrm{sum}` in [4]_.



