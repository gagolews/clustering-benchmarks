(sec:external-validity-measures)=
# External Cluster Validity Measures

In this section we review the external cluster validity scores that are implemented
in the [*genieclust*](https://genieclust.gagolewski.com/) package for Python
and R {cite}`genieclust` and discussed in detail in {cite}`aaa`
(this section contains excerpts therefrom).



Let $\mathbf{y}$ be a {ref}`label <sec:true-vs-predicted>`
vector representing {ref}`one <sec:many-partitions>` of the reference
$k$-partitions $\{X_1,\dots,X_k\}$ of a benchmark dataset $X$,
where $y_i\in[1:k]$ gives the true cluster number (ID) of the $i$-th object.

Furthermore, let $\hat{\mathbf{y}}$ be a label vector
encoding another partition, $\{\hat{X}_1,\dots,\hat{X}_k\}$,
which we would like to *relate* to the reference one, $\mathbf{y}$.
In our context, we assume that $\hat{\mathbf{y}}$ has been determined by some
clustering algorithm.


::::{note}
Below we assume any potential {ref}`noise points <sec:noise-points>` in $X$ have
been removed before the data analysis.
::::



::::{proof:example}
As an illustration, we consider the two-dimensional
[`wut/x2`](https://github.com/gagolews/clustering-data-v1) dataset.

```{python}
import numpy as np
import pandas as pd
dataset = "https://github.com/gagolews/clustering-data-v1/raw/master/wut/x2"
X = np.loadtxt(dataset + ".data.gz")
```

The reference partition consists of $k=3$ clusters:

```{python}
y_true = np.loadtxt(dataset+".labels0.gz", dtype=np.intc)
k = max(y_true)
```

We are going to relate it to
the results generated by the three following clustering algorithms ($l=k=3$).
First, [Genie](https://genieclust.gagolewski.com) with the default settings
in place:

```{python}
import genieclust
g = genieclust.Genie(n_clusters=k)  # default parameters
y_genie = g.fit_predict(X) + 1
```

Second, the 3-means method as implemented in
[*scikit-learn*](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html):

```{python}
import sklearn.cluster
c = sklearn.cluster.KMeans(n_clusters=k, n_init=123, random_state=123)
y_km = c.fit_predict(X) + 1
```

Third, an imaginary dummy "algorithm" that output a random partition:

```{python}
np.random.seed(123)
y_random = np.random.choice(np.arange(k), len(y_true)) + 1  # sample from 1..k
```

Below are the scatterplots depicting the four clusterings.
Actually, both Genie and the 3-means method generated quite reasonable
partitions (as we mentioned in {ref}`an earlier section <sec:many-partitions>`,
there might be many equally valid groupings) but we want to relate
them to a given reference set.

```{python echo=FALSE}
plt.figure(figsize=(plt.rcParams["figure.figsize"][0], )*2)  # HIDDEN
np.random.seed(123)  # HIDDEN
```

```{python partition-similarity-example-4,results="hide",fig.cap="The reference partition and three different clusterings that we would like to relate thereto"}
plt.subplot(2, 2, 1)
genieclust.plots.plot_scatter(X, labels=y_true-1, title="true", axis="equal")
plt.subplot(2, 2, 2)
genieclust.plots.plot_scatter(X, labels=y_genie-1, title="Genie", axis="equal")
plt.subplot(2, 2, 3)
genieclust.plots.plot_scatter(X, labels=y_km-1, title="k-means", axis="equal")
plt.subplot(2, 2, 4)
genieclust.plots.plot_scatter(X, labels=y_random-1, title="random", axis="equal")
plt.show()
```

```{python echo=FALSE,results="hide"}
plt.close()  # resets graphical params
```
::::



## Why Not Accuracy?

Furthermore, let $\mathbf{C}$ be the confusion matrix,
that is, a matrix with
$k$ rows and $l$ columns,
where, $c_{u,v}$ gives the number point indexes $i$ for which $y_i=u$
and $\hat{y}_v$. In other words, $c_{u,v}$ gives the number of points
from the $u$-th reference cluster that the clustering algorithm
classified as belonging to the $v$-th group.

TODO: citations


```{python}
# (C := genieclust.compare_partitions.confusion_matrix(y_true, y_pred))
```




normalized_confusion_matrix
pivoting... permutes the rows and columns
        so that the sum of the elements of the main diagonal is the largest
        possible



say that this is different than accuracy in classification





genieclust:: bibliography, compare_partitions.pyx

some axioms

Every index except `mi_score` (which computes the mutual
information score) outputs the value of 1.0 if two identical partitions
are given.
Note that partitions are always defined up to a bijection of the set of
possible labels, e.g., (1, 1, 2, 1) and (4, 4, 2, 4)
represent the same 2-partition.

    .. [1]
        Hubert L., Arabie P., Comparing Partitions,
        *Journal of Classification* 2(1), 1985, 193-218.

    .. [2]
        Rendon E., Abundez I., Arizmendi A., Quiroz E.M.,
        Internal versus external cluster validation indexes,
        *International Journal of Computers and Communications* 5(1), 2011,
        27-34.

    .. [3]
        Rezaei M., Franti P., Set matching measures for external cluster validity,
        *IEEE Transactions on Knowledge and Data Mining* 28(8), 2016,
        2173-2186. https://doi.org/10.1109/TKDE.2016.2551240.

    .. [4]
        Vinh N.X., Epps J., Bailey J.,
        Information theoretic measures for clusterings comparison:
        Variants, properties, normalization and correction for chance,
        *Journal of Machine Learning Research* 11, 2010, 2837-2854.

`normalized_accuracy` is defined as
:math:`(\\mathrm{Accuracy}(C_\\sigma)-1/L)/(1-1/L)`,
where :math:`C_\\sigma` is a version of the confusion matrix
for given `x` and `y`, :math:`K \\leq L`, with columns permuted
based on the solution to the Maximal Linear Sum Assignment Problem
(see `normalize_confusion_matrix`).
:math:`\\mathrm{Accuracy}(C_\\sigma)` is sometimes referred to as Purity,
e.g., in [2]_.

`pair_sets_index` gives the Pair Sets Index (PSI)
adjusted for chance [3]_, :math:`K \\leq L`.
Pairing is based on the solution to the Linear Sum Assignment Problem
of a transformed version of the confusion matrix.




`rand_score` gives the Rand score (the "probability" of agreement
between the two partitions) and `adjusted_rand_score` is its version
corrected for chance [1]_ (especially Eqs. (2) and (4) therein):
its expected value is 0.0 for two independent
partitions. Due to the adjustment, the resulting index might also
be negative for some inputs.

Similarly, `fm_score` gives the Fowlkes-Mallows (FM) score
and `adjusted_fm_score` is its adjusted-for-chance version [1]_.

Note that both the (unadjusted) Rand and FM scores are bounded from below
by :math:`1/(K+1)` if :math:`K = L`, hence their adjusted versions
are preferred.

`mi_score`, `adjusted_mi_score` and `normalized_mi_score` are
information-theoretic indices based on mutual information,
see the definition of :math:`\\mathrm{AMI}_\\mathrm{sum}`
and :math:`\\mathrm{NMI}_\\mathrm{sum}` in [4]_.



TODO: citations

The Rand index (1971):

$$
R(\mathbf{C}) = \frac{ {n \choose 2} + 2 \sum_{i,j\in[k]} {c_{i,j}\choose 2}
                  - \sum_{i\in[k]} {c_{i,\cdot}\choose 2}
                  - \sum_{j\in[k]} {c_{\cdot,j}\choose 2}
    }{{n\choose 2}},
$$

under the assumption that ${0\choose 2}={1\choose 2}=0$.


The normalised total number of pairs
$\{\vect{x}_i, \vect{x}_j\}$
with ($u_i=u_j$ and $v_i=v_j$) or ($u_i\neq u_j$ and $v_i\neq v_j$).


\vfill
\bigskip\hrule\bigskip

\tiny

Other (similar) measures: e.g., the Fowlkes--Mallows index,
see Hubert L., Comparing Partitions, {\it Journal of Classification} {\bf 2}, 1985, pp.~193--218 and also M.~Rezaei and P. Fränti. Set matching measures for external cluster validity. \textit{IEEE Transactions on Knowledge and Data Engineering} {\bf 28}(8), 2016, pp.~2173–2186. doi:10.1109/TKDE.2016.2551240.

\nocite{psi}

\end{frame}

\begin{frame}[fragile]\slidetitleA{Comparing Partitions}

Properties:
\begin{itemize}
 \pause\item For every $\mathbf{C}$, $R(\mathbf{C})\ge 0$ and if $\vect{u}=\vect{v}$, then $R(\mathbf{C})=1$;
 \pause\item if $\sigma$ is a permutation of $[k]$
and $\mathbf{C}'$ is such that $c_{i,j}'=c_{i,\sigma(j)}$,
then $R(\mathbf{C})=R(\mathbf{C}')$;
\pause\item if $c_{i,j}=m$ for all $i,j$ and given $k$,
then $R(\mathbf{C}) \stackrel{m\to\infty}{\to} 1-\frac{2(k-1)}{k^2}$.
% \pause\item if $c_{i,j}=m$ for all $j$ and $i=1$ and $c_{i,j}=0$ otherwise,
% then
% $R(\mathbf{C}) \stackrel{m\to\infty}{\to} 1-\frac{k-1}{k}=\frac{1}{k}$.
\end{itemize}
\pause
$\Rightarrow$ The need for a {\color{red2}\bf ``correction for chance''}:

\pause
we'd like the expected index to be equal to $0$ if the
partitions were ``picked at random''.

\medskip\pause
If both $k$-partitions are picked at random, subject to having the original
number of classes and objects in each,
then $
 \mathbb{E}\,  {c_{i,j}\choose 2} =
 \frac{{c_{i,\cdot}\choose 2}{c_{\cdot,j}\choose 2}}{{n\choose 2}}.
$


\bigskip\pause
This yields the \textbf{Adjusted Rand Index} {cite}`comparing_partitions`:

$$
\mathrm{AR}(\mathbf{C})=\tfrac{ \mathrm{R}(\mathbf{C})-\mathbb{E}\,\mathrm{R}(\mathbf{C})}{1-\mathbb{E}\,\mathrm{R}(\mathbf{C})}=
\frac{ \sum_{i,j\in[k]} {c_{i,j}\choose 2}
 - \sum_{i\in[k]} {c_{i,\cdot}\choose 2}
   \sum_{j\in[k]} {c_{\cdot,j}\choose 2} / {n\choose 2}
    }{
     \sum_{i\in[k]} {c_{i,\cdot}\choose 2}/2
   +\sum_{j\in[k]} {c_{\cdot,j}\choose 2}/2
 - \sum_{i\in[k]} {c_{i,\cdot}\choose 2}
   \sum_{j\in[k]} {c_{\cdot,j}\choose 2} / {n\choose 2}
    },
$$

% {\footnotesize\color{gray}
% % see Hubert L., Comparing Partitions, {\it Journal of Classification} {\bf 2}, 1985, p.~193--218.
% }


TODO: ARI

TODO: some axioms


