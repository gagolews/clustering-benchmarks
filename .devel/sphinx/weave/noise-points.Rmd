(sec:noise-points)=
# Noise Points


Some datasets feature **noise points**
to make the clustering problem more difficult.
They are specially marked in the ground-truth vectors (cluster ID=0).


For example, consider the {ref}`other/hdbscan <sec:data-v1>` dataset
{cite}`hdbscanpkg`, which consists of 2309 points in $\mathbb{R}^2$.

```{python}
import numpy as np
import pandas as pd
dataset = "https://github.com/gagolews/clustering-data-v1/raw/master/other/hdbscan"
X = np.loadtxt(dataset + ".data.gz")
```

Loading the true labels:

```{python}
y_true = np.loadtxt(dataset+".labels0.gz", dtype=np.intc)
```

Here is a summary of the number of points in each cluster:

```{python}
pd.Series(y_true).value_counts()
```

We see that there are six clusters (1â€“6)
and a special point group with ID of 0 that marks
some points as noise (see the lefthand side plot in the figure below).



Suppose we want to evaluate how [Genie](https://genieclust.gagolewski.com)
handles such a noisy dataset. Of course, the algorithm must
not know about the presence of such problematic points. After all,
it is an unsupervised learning task.

```{python}
import genieclust
k = np.max(y_true)  # number of clusters to detect
g = genieclust.Genie(n_clusters=k)  # using default parameters
y_pred = g.fit_predict(X) + 1  # +1 makes cluster IDs in 1..k, not 0..(k-1)
```

Below we plot the reference and the predicted partitions.
Additionally, we draw a version of `y_pred` whose noise point markers
are propagated from `y_true` (as a kind of data postprocessing).

```{python partition-similarity-example-noise,results="hide",fig.cap="....."}
plt.subplot(1, 3, 1)
genieclust.plots.plot_scatter(X, labels=y_true-1, axis="equal", title="y_true")
plt.subplot(1, 3, 2)
genieclust.plots.plot_scatter(X, labels=y_pred-1, axis="equal", title="y_pred")
plt.subplot(1, 3, 3)
y_pred2 = np.where(y_true > 0, y_pred, 0)  # y_pred, but noise points get ID=0
genieclust.plots.plot_scatter(X, labels=y_pred2-1, axis="equal",
    title="y_pred (noise from y_true)")
plt.show()
```


Here is the confusion matrix:

```{python}
genieclust.compare_partitions.confusion_matrix(y_true, y_pred)
```

The first row denotes the "noise cluster": we do not actually
care how the algorithm classifies such points. After all, most classical
algorithms are not equipped with noise point detectors[^footnoisedetect]
and they should not be penalised for this.
Genie discovered four clusters very well (3, 4, 5, 6),
but failed on the first two (it created a "combined" cluster instead
and considered some noise points as a separate point group).

::::{important}
When computing external cluster validity measures, we should omit the
noise points whatsoever.
::::


We can thus compute the adjusted asymmetric accuracy,
ignoring the first row in the confusion matrix:

```{python}
genieclust.compare_partitions.adjusted_asymmetric_accuracy(
    y_true[y_true>0],
    y_pred[y_true>0]
)
```

The score is somewhere between 4/6 (four clusters discovered correctly)
and 5/6 (one cluster definitely missed).



[^footnoisedetect]: Some algorithms have built-in noise point detectors
    (e.g., [HDBSCAN\*](https://hdbscan.readthedocs.io/en/latest/)
    and [Genie](https://genieclust.gagolewski.com)).
    These can also be evaluated using some of the datasets from our battery,
    but we are not interested in this problem in the current context.
