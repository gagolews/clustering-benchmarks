(sec:true-vs-predicted)=
# True vs Predicted Clusters


## Motivation

Let $X=\{\mathbf{x}_1, \dots, \mathbf{x}_n\}$ be the **input dataset**
that consists of $n$ objects.

As an illustration, in this section we consider
the [`wut/x2`](https://github.com/gagolews/clustering-data-v1) dataset,
which consists of 120 points in $\mathbb{R}^2$.

```{python}
import numpy as np
import pandas as pd
dataset = "https://github.com/gagolews/clustering-data-v1/raw/master/wut/x2"
X = np.loadtxt(dataset + ".data.gz")
X[:5, :]  # preview
```

::::{note}
The code below should be quite self-explanatory even to the readers
who do not know Python. To learn more about this environment
check out Marek's recent open-access (free!) textbook
[Minimalist Data Wrangling in Python](https://datawranglingpy.gagolewski.com/)
{cite}`datawranglingpy`.
Also note that in a {ref}`further section <sec:how-to-access>`,
we explain how to use our benchmark framework in R or Matlab.
::::


With each dataset like the one above,
we are given a **reference[^footmanyreference]
partition** assigned by experts, representing
a desired grouping of the points into $k \ge 2$ clusters.

[^footmanyreference]: {ref}`Later <sec:many-partitions>` we will note
    that there may be many possible ways to split a dataset into groups.



```{python}
(y_true := np.loadtxt(dataset+".labels0.gz", dtype=np.intc))
```


More formally, we have here a
$k$-partition[^footpart] $\{X_1,\dots,X_k\}$ of $X$
encoded using a **label vector**[^footsurj] $\mathbf{y}$, where
$y_i\in[1:k]$ gives the subset number (ID) of the $i$-th object.


[^footpart]: We say that $\{X_1,\dots,X_k\}$ is a $k$-partition of $X$,
    whenever $\bigcup_{i=1}^k X_i=X$, each $X_i$ is nonempty,
    and the subsets are pairwise disjoint, i.e., $X_i\cap X_j=\emptyset$
    for $i\neq j$.

[^footsurj]: More precisely, a surjection $[1:n]\stackrel{\text{onto}}{\to}[1:k]$.


The number of subsets $k\ge 2$ is thus an inherent part of the
reference set.

```{python}
(k := np.max(y_true))
```

<!--
```{python}
np.histogram(y_true, return_count=True)
```

There are thus 50 points in the 1st cluster,
40 points in the 2nd group,
and 30 points in the 3rd set.
-->


Now, let's say that we have **a clustering algorithm whose usefulness
we would like to assess**. We apply it on $X$ to **discover a new
$k$-partition**.

For example, let's consider the output of the
[*Genie*](https://genieclust.gagolewski.com) algorithm:

```{python}
import genieclust
g = genieclust.Genie(n_clusters=k)  # using default parameters
(y_pred := g.fit_predict(X) + 1)  # +1 makes cluster IDs in 1..k, not 0..(k-1)
```

We thus obtained a vector of **predicted labels** $\hat{\mathbf{y}}$
encoding a new grouping, $\{\hat{X}_1,\dots,\hat{X}_k\}$.

The figure below depicts the two partitions side by side.
Intuitively, we can thus consider clustering a method to
assign colours to all the input points.


```{python partition-similarity-example-2,results="hide",fig.cap="Two example partitions that we would like to compare"}
plt.subplot(1, 2, 1)
genieclust.plots.plot_scatter(X, labels=y_true-1, axis="equal", title="y_true")
plt.subplot(1, 2, 2)
genieclust.plots.plot_scatter(X, labels=y_pred-1, axis="equal", title="y_pred")
plt.show()
```

::::{important}
Ideally, we would like to work with algorithms that yield partitions
closely matching the reference ones on as wide a set of problems
as possible.
::::

Our aim is therefore to *relate* the predicted labels to the reference ones.
Note that the automated discovery of $\hat{\mathbf{y}}$
never relies on the information included in $\mathbf{y}$.
In other words, clustering is an unsupervised[^footsemisupervised]
learning process.


[^footsemisupervised]: Tasks such as semi-supervised clustering,
    where the right assignment of *some* of the input points is known in
    advance, are of our interest here. However, the current framework can
    trivially be adjusted to fit such scenarios.




## Permuting Cluster IDs

A partition is a *set* of point groups, and sets are, by definition, unordered.
Therefore, the **actual cluster IDs do not really matter**.

Looking at the above figure, we see that
the red (ID=2), black (ID=1), and green (ID=3) discovered clusters
can be paired with, respectively,
the black (ID=1), red (ID=2), and green (ID=3) reference ones.

We can easily recode[^footmanualrelabel] `y_pred`
so that the cluster IDs nicely correspond to each other:


```{python}
o = np.array([2, 1, 3])  # relabelling: 1→2, 2→1, 3→3
(y_pred := o[y_pred-1])  # Python uses 0-based indexing, hence the -1
```

See below for an updated figure.


```{python partition-similarity-example-2b,results="hide",fig.cap="The two partitions after the cluster ID (colour) matching"}
plt.subplot(1, 2, 1)
genieclust.plots.plot_scatter(X, labels=y_true-1, axis="equal", title="y_true")
plt.subplot(1, 2, 2)
genieclust.plots.plot_scatter(X, labels=y_pred-1, axis="equal", title="y_pred")
plt.show()
```


[^footmanualrelabel]: In a
    {ref}`later section <sec:partition-similarity-scores>` we discuss a way
    to automatically discover an optimal relabelling based on the solution
    to the maximal assignment problem.



## Confusion Matrix

We can determine the confusion matrix $\mathbf{C}$ for the two label vectors:

```{python}
genieclust.compare_partitions.confusion_matrix(y_true, y_pred)
```

Here, $c_{u, v}$ denotes the number of points in the $u$-th reference cluster
that the algorithm assigned to the $v$-th cluster.

Overall, *Genie* returned a clustering quite similar to the reference one.
$c_{1,1}+c_{2, 2}+c_{3,3}=37+40+30=107$ out of the $120$ input points.
In particular, all the red and green reference points (the 2nd and the 3rd row)
have been assigned correctly.

However, $12$ red points and $1$ green point should be coloured black.


## Measuring Partition Similarity

A confusion matrix nicely summarises all the information we need to
judge the clustering quality. However,
if we wish to compare the quality of different algorithms,
we would rather have the information summarised in the form of a single number.

The **adjusted Rand index** {cite}`comparing_partitions`, $\mathrm{AR}$, which
we define formally in the {ref}`Appendix <sec:partition-similarity-scores>`,
is one of the many *partition similarity scores*.
We can use it to quantify the agreement between $\mathbf{y}$ and
$\hat{\mathbf{y}}$, and thus assess the degree to which the output of
a clustering algorithm matches the reference (ground truth) labels.

The greater the number[^footar] of point pairs that both belong to either
the same or different reference and predicted clusters, the greater
the similarity score.

[^footar]: The number of $(i,j)$s such that either
    ($y_i=y_j$ and $\hat{y}_i=\hat{y}_j$) or
    ($y_i\neq y_j$ and $\hat{y}_i\neq \hat{y}_j$).

This measure is normalised in such a way that if two partitions are identical,
then $\mathrm{AR}(\mathbf{y}, \hat{\mathbf{y}})=1$. Furthermore, it is adjusted
for chance: its expected value is equal to $0$ if the partitions were picked
at random. Also, the relabelling of cluster ID (see above) does not affect
the score.



<!-- TODO -->

For example:

```{python}
genieclust.compare_partitions.adjusted_rand_score(y_true, y_pred)
```

indicates a decent degree of similarity between the reference
and the discovered partitions.





More partition similarity scores are discussed
in the {ref}`Appendix <sec:external-validity-measures>`.
This is also where we explain in more detail why **accuracy**,
which is a measure popular in classification tasks,
**should not be used in clustering problems**,
at least not without a prior cluster relabelling which we mentioned above.
