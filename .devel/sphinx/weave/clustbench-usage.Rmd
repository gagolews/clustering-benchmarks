(sec:clustbench-usage)=
# Using *clustbench*

The Python version of the *clustering-benchmarks* package
can be installed from [PyPI](https://pypi.org/project/clustering-benchmarks/),
e.g., via a call to:

```
pip3 install clustering-benchmarks
```

from the command line. Alternatively, please use your favourite Python
package manager.


Once installed, we can import it by calling:

```{python}
import clustbench
```

Below we discuss its basic features/usage.


::::{note}
*To learn more about Python, check out Marek's open-access (free!) textbook*
[Minimalist Data Wrangling in Python](https://datawranglingpy.gagolewski.com/)
{cite}`datawranglingpy`.
::::


## Fetching Benchmark Data

The datasets from the {ref}`sec:suite-v1` can be accessed easily.
It is best to [download](https://github.com/gagolews/clustering-data-v1/releases/tag/v1.1.0)
the whole repository onto our disk first.
Let us assume they are available in the following directory:

```{python}
# load from a local library (download the suite manually)
import os.path
data_path = os.path.join("~", "Projects", "clustering-data-v1")
```

Here is the list of the currently available benchmark batteries
(dataset collections):

```{python}
print(clustbench.get_battery_names(path=data_path))
```

We can list the datasets in an example battery by calling:

```{python}
battery = "wut"
print(clustbench.get_dataset_names(battery, path=data_path))
```

For instance, let us load the `wut/x2` dataset:


```{python}
dataset = "x2"
b = clustbench.load_dataset(battery, dataset, path=data_path)
```

The above call returned a named tuple. For instance, the corresponding README
file can be inspected by accessing the `description` field:

```{python}
print(b.description)
```

Moreover, the `data` field gives the data matrix, `labels` is the list
of all ground truth partitions (encoded as label vectors),
and `n_clusters` gives the corresponding numbers of subsets.
In case of any doubt, we can always consult the official documentation
of the {any}`clustbench.load_dataset` function.

::::{note}
Particular datasets can be retrieved from an online repository directly
(no need to download the whole battery first) by calling:

```{python}
data_url = "https://github.com/gagolews/clustering-data-v1/raw/v1.1.0"
b = clustbench.load_dataset("wut", "x2", url=data_url)
```
::::

For instance, here is the shape (*n* and *d*) of the data matrix,
the number of reference partitions, and their cardinalities *k*,
respectively:

```{python}
print(b.data.shape, len(b.labels), b.n_clusters)
```

The following figure (generated via a call to
[`genieclust`](https://genieclust.gagolewski.com/)`.plots.plot_scatter`)
illustrates the benchmark dataset at hand.

```{python using-clustbench-example1,results="hide",fig.cap="An example benchmark dataset and the corresponding ground truth labels."}
import genieclust
for i in range(len(b.labels)):
    plt.subplot(1, len(b.labels), i+1)
    genieclust.plots.plot_scatter(
        b.data, labels=b.labels[i]-1, axis="equal", title=f"labels{i}"
    )
plt.show()
```


## Fetching Precomputed Results

Let us study one of the sets of
[precomputed clustering results](https://github.com/gagolews/clustering-results-v1)
stored in the following directory:


```{python}
results_path = os.path.join("~", "Projects", "clustering-results-v1", "original")
```

They can be fetched by calling:

```{python}
method_group = "Genie"  # or "*" for everything
res = clustbench.load_results(
    method_group, b.battery, b.dataset, b.n_clusters, path=results_path
)
print(list(res.keys()))
```

We thus have got access to precomputed data
generated by the [*Genie*](https://genieclust.gagolewski.com)
algorithm with different `gini_threshold` parameter settings.



## Computing External Cluster Validity Measures


Different
{ref}`external cluster validity measures <sec:external-validity-measures>`
can be computed by calling {any}`clustbench.get_score`:


```{python}
pd.Series({  # for aesthetics
    method: clustbench.get_score(b.labels, res[method])
    for method in res.keys()
})
```

By default, normalised clustering accuracy is applied.
As explained in the tutorial, we compare the predicted clusterings against
{ref}`all <sec:many-partitions>` the reference partitions
({ref}`ignoring noise points <sec:noise-points>`)
and report the maximal score.

Let us depict the results for the `"Genie_G0.3"` method:

```{python using-clustbench-example2,results="hide",fig.cap="Results generated by Genie."}
method = "Genie_G0.3"
for i, k in enumerate(res[method].keys()):
    plt.subplot(1, len(res[method]), i+1)
    genieclust.plots.plot_scatter(
        b.data, labels=res[method][k]-1, axis="equal", title=f"{method}; k={k}"
    )
plt.show()
```


## Applying Clustering Methods Manually

Naturally, the aim of this benchmark framework is also to test new methods.
We can use {any}`clustbench.fit_predict_many` to generate
all the partitions required to compare ourselves against the reference labels.

For instance, let us investigate the behaviour of the k-means algorithm:

```{python}
import sklearn.cluster
m = sklearn.cluster.KMeans(n_init=10)
res["KMeans"] = clustbench.fit_predict_many(m, b.data, b.n_clusters)
clustbench.get_score(b.labels, res["KMeans"])
```

We see that k-means (which specialises in detecting symmetric Gaussian-like blobs)
performs better than *Genie* on this particular dataset.

```{python using-clustbench-example3,results="hide",fig.cap="Results generated by K-Means."}
method = "KMeans"
for i, k in enumerate(res[method].keys()):
    plt.subplot(1, len(res[method]), i+1)
    genieclust.plots.plot_scatter(
        b.data, labels=res[method][k]-1, axis="equal", title=f"{method}; k={k}"
    )
plt.show()
```

For more functions, please refer to the package's documentation (in the next section).
Moreover, {ref}`sec:colouriser` describes a standalone application
that can be used to prepare our own two-dimensional datasets.

Note that you do not have to use the *clustering-benchmark* package
to access the benchmark datasets from our repository.
The {ref}`sec:how-to-access` section mentions that most operations
involve simple operations on files and directories which you can
implement manually. The package was developed merely for the users'
convenience.
